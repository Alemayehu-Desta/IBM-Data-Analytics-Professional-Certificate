{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# **Web Scraping Lab**\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Estimated time needed: **30** minutes\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Objectives\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "After completing this lab you will be able to:\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "* Download a webpage using requests module\n* Scrape all links from a web page\n* Scrape all image urls from a web page\n* Scrape data from html tables\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Scrape www.ibm.com\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Import the required modules and functions\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from bs4 import BeautifulSoup # this module helps in web scrapping.\nimport requests  # this module helps us to download a web page",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Download the contents of the web page\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "url = \"http://www.ibm.com\"",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text ",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a soup object using the class BeautifulSoup\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "soup = BeautifulSoup(data,\"html5lib\")  # create a soup object using the variable 'data'",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "FeatureNotFound",
                    "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml5lib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/bs4/__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Scrape all links\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for link in soup.find_all('a'):  # in html anchor/link is represented by the tag <a>\n    print(link.get('href'))",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'soup' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m \u001b[43msoup\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# in html anchor/link is represented by the tag <a>\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Scrape  all images\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n    print(link.get('src'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Scrape data from html tables\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#The below url contains a html table with data about colors and color codes.",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "soup = BeautifulSoup(data,\"html5lib\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#find a html table in the web page\ntable = soup.find('table') # in html table is represented by the tag <table>",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Get all rows from the table\nfor row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n    # Get all columns in each row.\n    cols = row.find_all('td') # in html a column is represented by the tag <td>\n    color_name = cols[2].getText() # store the value in column 3 as color_name\n    color_code = cols[3].getText() # store the value in column 4 as color_code\n    print(\"{}--->{}\".format(color_name,color_code))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Authors\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Ramesh Sannareddy\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Other Contributors\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Rav Ahuja\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Change Log\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n|---|---|---|---|\n| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.10",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}